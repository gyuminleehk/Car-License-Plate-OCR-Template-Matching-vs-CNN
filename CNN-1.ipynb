{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load the CSV file\ndata = pd.read_csv('_annotations11.csv')   # dataset\ndata_test = pd.read_csv('_annotatetest11.csv') #testset\n\n# Split the data into images and labels\nfilenames = data['filename']        # dataset\nlabels = data['class']\nxmins = data['xmin']\nymins = data['ymin']\nxmaxs = data['xmax']\nymaxs = data['ymax']\n\nfilenames_test = data_test['filename']         #testset\nlabels_test = data_test['class']       \nxmins_test = data_test['xmin']\nymins_test = data_test['ymin']\nxmaxs_test = data_test['xmax']\nymaxs_test = data_test['ymax']\n\n# Convert labels to integers\nlabel_to_int = {label: i for i, label in enumerate(labels.unique())}\nint_to_label = {i: label for label, i in label_to_int.items()}\nlabels = labels.map(label_to_int)\n\n# Preprocess the images for dataset\nimages = []\nsegmented_images = []\nsegmented_labels = []\n\nfor i in range(len(filenames)):\n    filename = filenames[i]\n    xmin = xmins[i]\n    ymin = ymins[i]\n    xmax = xmaxs[i]\n    ymax = ymaxs[i]\n    \n    image = load_img(filename, target_size=(32, 32))\n    image = img_to_array(image) / 255.0  # Normalize pixel values to [0, 1]\n    images.append(image)\n    \n    # Perform character segmentation\n    plate_image = load_img(filename)\n    character_image = plate_image.crop((xmin, ymin, xmax, ymax))\n    character_image = character_image.resize((32, 32))\n    character_array = img_to_array(character_image) / 255.0\n    segmented_images.append(character_array)\n    segmented_labels.append(labels[i])\n    \n\nimages = np.array(images)\nsegmented_images = np.array(segmented_images)\nsegmented_labels = np.array(segmented_labels)\n\n# Preprocess the images for testset\nimages_test = []\nsegmented_images_test = []\nsegmented_labels_test = []\n\nfor i in range(len(filenames_test)):\n    filename_test = filenames_test[i]\n    xmin_test = xmins_test[i]\n    ymin_test = ymins_test[i]\n    xmax_test = xmaxs_test[i]\n    ymax_test = ymaxs_test[i]\n    \n    image_test = load_img(filename_test, target_size=(32, 32))\n    image_test = img_to_array(image_test) / 255.0  # Normalize pixel values to [0, 1]\n    images_test.append(image_test)\n    \n    # Perform character segmentation\n    plate_image_test = load_img(filename_test)\n    character_image_test = plate_image_test.crop((xmin_test, ymin_test, xmax_test, ymax_test))\n    character_image_test = character_image_test.resize((32, 32))\n    character_array_test = img_to_array(character_image_test) / 255.0\n    segmented_images_test.append(character_array_test)\n    segmented_labels_test.append(labels_test[i])\n\nimages_test = np.array(images_test)\nsegmented_images_test = np.array(segmented_images_test)\nsegmented_labels_test = np.array(segmented_labels_test)\n\n# Split the data into training and testing sets\n#train_images, test_images, train_labels, test_labels = train_test_split(segmented_images, segmented_labels, test_size=0.2, random_state=42)\ntrain_images=segmented_images\ntrain_labels=segmented_labels\n\ntest_images=segmented_images_test\ntest_labels=segmented_labels_test\n\n# Apply data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=False,\n    fill_mode='nearest'\n)\ndatagen.fit(train_images)\n\n# Define the CNN model\nmodel = tf.keras.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(len(label_to_int), activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Train the model with data augmentation\nmodel.fit(datagen.flow(train_images, train_labels, batch_size=32),\n          epochs=20)\n          #validation_data=(test_images, test_labels))\n\n'''\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\nprint('Test accuracy:', test_acc)\n'''\n\n# Make predictions\npredictions = model.predict(test_images)\npredicted_classes = np.argmax(predictions, axis=1)\n\n# Map the predicted class indices back to the corresponding labels\npredicted_labels = [int_to_label[idx] for idx in predicted_classes]\n\n# Combine the filenames and their corresponding predicted labels\nresults = [f\"Filename: {filenames_test[i]}, Predicted label: {predicted_labels[i]}, Actual label: {labels_test[i]}\" for i in range(len(test_images))]  \n\n# Join the results into a single string\noutput_string = \"\\n\".join(results)\nprint(output_string)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}