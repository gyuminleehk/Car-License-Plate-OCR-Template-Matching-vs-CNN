{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom PIL import Image, ImageOps, ImageChops\nimport cv2\nimport numpy as np\nimport os\n\n# Function to load templates using Pillow\ndef load_templates(template_dir):\n    templates = {}\n    for filename in os.listdir(template_dir):\n        if filename.endswith('.png'):\n            label = filename.split('.')[0]\n            template_path = os.path.join(template_dir, filename)\n            template = Image.open(template_path).convert('L')\n            templates[label] = template\n    return templates\n\n# Function to perform OCR using correlation-based method\ndef ocr_correlation(segment, templates):\n    segment = ImageOps.invert(segment)  \n    segment = np.array(segment, dtype=np.uint8)\n    segment = cv2.threshold(segment, 127, 255, cv2.THRESH_BINARY)[1]  # Ensure binary image\n\n    best_match = None\n    best_score = -1\n    for label, template in templates.items():\n        template = ImageOps.invert(template)\n        template = np.array(template, dtype=np.uint8)\n        template = cv2.threshold(template, 127, 255, cv2.THRESH_BINARY)[1]  # Ensure binary image\n        if template.shape[0] <= segment.shape[0] and template.shape[1] <= segment.shape[1]:  # Ensure template is not larger than segment\n            result = cv2.matchTemplate(segment, template, cv2.TM_CCOEFF_NORMED)\n            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n            if max_val > best_score:\n                best_score = max_val\n                best_match = label\n\n    return best_match\n\n# Function to segment the input image using Pillow\ndef segment_image(input_image, x_min, y_min, x_max, y_max):\n    return input_image.crop((x_min, y_min, x_max, y_max))\n\n# Function to calculate accuracy\ndef calculate_accuracy(recognized_labels, true_labels):\n    correct = sum(1 for rec, true in zip(recognized_labels, true_labels) if rec == true)\n    return correct / len(true_labels)\n\n# Main function\ndef main():\n    template_dir = 'templates'  # Update this path to your templates directory\n    images_dir = 'input_images' # Directory containing the input images\n    input_segmented_image = '_annotatetest11.csv' # CSV file with segmented image from part 3\n\n    # Load ground truth labels\n    input_segmented_image_df = pd.read_csv(input_segmented_image)\n    \n    results = []\n    true_labels = []\n\n    # Load templates\n    templates = load_templates(template_dir)\n\n    for index, row in input_segmented_image_df.iterrows():\n        input_image_path = os.path.join(images_dir, row['filename'])\n        true_label = row['class']\n        truestring= row['class']\n        xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n\n        # Load the input image using Pillow\n        input_image = Image.open(input_image_path).convert('L')\n\n        # Segment the input image\n        segment = segment_image(input_image, xmin, ymin, xmax, ymax)\n\n        inv_img = ImageChops.invert(segment)  # Invert the image (black to white or white to black)\n        inv_img = inv_img.resize((28, 28))\n        \n        # Perform OCR on the segmented image\n        recognized_character = ocr_correlation(inv_img, templates)\n        results.append((row['filename'], recognized_character,truestring ))\n        true_labels.append(true_label)\n\n    # Calculate accuracy\n    recognized_labels = [rec[1] for rec in results]\n    accuracy = calculate_accuracy(recognized_labels, true_labels)\n    \n    # Print each filename with its recognized string\n    for filename, recognized_string,truestring in results:\n        print(f'Filename: {filename}, Recognized String: {recognized_string}, Actual String: {truestring}')\n    \n    print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n\nif __name__ == '__main__':\n    main()\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}